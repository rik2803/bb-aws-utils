# shellcheck source=../../bb-aws-utils/lib/common.bash
[[ -z ${LIB_COMMON_LOADED} ]] && { source "${LIB_DIR:-lib}/common.bash"; }
# shellcheck source=../../bb-aws-utils/lib/install.bash
[[ -z ${LIB_INSTALL_LOADED} ]] && { source "${LIB_DIR:-lib}/install.bash"; }
# shellcheck source=../../bb-aws-utils/lib/bitbucket.bash
[[ -z ${LIB_BITBUCKET_LOADED} ]] && { source "${LIB_DIR:-lib}/bitbucket.bash"; }

export LIB_AWS_S3_ARTIFACT_LOADED=1

AWS_S3_CLI_OPTS=""
if ! is_debug_enabled; then
  AWS_S3_CLI_OPTS="--quiet"
else
  AWS_S3_CLI_OPTS="--debug"
fi

aws_s3_generate_zip_filename() {
  check_envvar PARENT_SLUG R

  if bb_is_config_repo; then
    info "This is a config repo"
    if [[ -z ${AWS_S3_FILENAME_SUFFIX} ]]; then
      echo "${PARENT_SLUG}-$(cat ${BB_AWS_UTILS_CLONE_DIR}/TAG)-${BITBUCKET_COMMIT}.zip"
    else
      info "Adding AWS_S3_FILENAME_SUFFIX to artifact name"
      echo "${PARENT_SLUG}-${AWS_S3_FILENAME_SUFFIX}-$(cat ${BB_AWS_UTILS_CLONE_DIR}/TAG)-${BITBUCKET_COMMIT}.zip"
    fi
  else
    info "This is not a config repo"
    if [[ -z ${AWS_S3_FILENAME_SUFFIX} ]]; then
      echo "${PARENT_SLUG}-${BITBUCKET_COMMIT}.zip"
    else
      info "Adding AWS_S3_FILENAME_SUFFIX to artifact name"
      echo "${PARENT_SLUG}-${AWS_S3_FILENAME_SUFFIX}-${BITBUCKET_COMMIT}.zip"
    fi
  fi
}

aws_s3_generate_parent_zip_filename() {
  check_envvar PARENT_SLUG R

  if bb_is_config_repo; then
    info "This is a config repo"
    if [[ -z ${AWS_S3_FILENAME_SUFFIX} ]]; then
      echo "${PARENT_SLUG}-$(cat ${BB_AWS_UTILS_CLONE_DIR}/TAG).zip"
    else
      info "Adding AWS_S3_FILENAME_SUFFIX to artifact name"
      echo "${PARENT_SLUG}-${AWS_S3_FILENAME_SUFFIX}-$(cat ${BB_AWS_UTILS_CLONE_DIR}/TAG).zip"
    fi
  else
    info "This is not a config repo"
    if [[ -z ${AWS_S3_FILENAME_SUFFIX} ]]; then
      echo "${PARENT_SLUG}-${BITBUCKET_COMMIT}.zip"
    else
      info "Adding AWS_S3_FILENAME_SUFFIX to artifact name"
      echo "${PARENT_SLUG}-${AWS_S3_FILENAME_SUFFIX}-${BITBUCKET_COMMIT}.zip"
    fi
  fi
}

#######################################
# aws_s3_create_artifact: Creates the build artifact ZIP file
#
# Expects:
#     * To be used in the repository that builds the code (i.e. non config repo's)
#     * Config repo's should use aws_s3_update_artifact to add files to the ZIP file
#     * Created file is ${PARENT_SLUG}-${BITBUCKET_COMMIT}.zip as generated by aws_s3_generate_zip_filename
#
# Globals:
#     * PARENT_SLUG: Set by bootstrapping bb-aws-utils
#     * BITBUCKET_REPO_SLUG: provided by BitBucket pipelines
#     * BITBUCKET_COMMIT: provided by BitBucket pipelines
#     * PAYLOAD_PATH: the folder that contains the tree that should end up in the ZIP, defaults to dist
#
# Arguments:
#
# Outputs:
#
# Returns:
#    * 0 on success
#    * 1 on failure
#
#######################################
aws_s3_create_artifact() {
  check_envvar PAYLOAD_PATH O "dist"
  bb_is_config_repo && fail "aws_s3_create_artifact should only be used in a non-config repo"
  install_zip

  info "Start creation of a zipped artifact file $(aws_s3_generate_zip_filename)"
  (cd "${PAYLOAD_PATH}" && zip "${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)" -r .)
  success "Zipped artifact file $(aws_s3_generate_zip_filename) successfully created"
}

#######################################
# aws_s3_upload_artifact: Uploads the artifact ZIP file to the S3 bucket ${ARTIFACT_BUCKET}
#
# Expects:
#     * Uploaded object name is ${PARENT_SLUG}-${BITBUCKET_COMMIT}.zip as generated by aws_s3_generate_zip_filename
#
# Globals:
#     * PARENT_SLUG: Set by bootstrapping bb-aws-utils
#     * BITBUCKET_REPO_SLUG: provided by BitBucket pipelines
#     * BITBUCKET_COMMIT: provided by BitBucket pipelines
#
# Arguments:
#     * ACL: optional, defaults to bucket-owner-full-control. For example private or public-read.
#
# Outputs:
#
# Returns:
#    * 0 on success
#    * exits on failure
#
#######################################
aws_s3_upload_artifact() {
  check_envvar ARTIFACT_BUCKET R

  local acl="bucket-owner-full-control"

  if [[ -n "${1}" ]]; then
    acl="${1}"
  fi

  info "Starting upload of $(aws_s3_generate_zip_filename) to S3 bucket ${ARTIFACT_BUCKET}"
  if aws s3 cp ${AWS_S3_CLI_OPTS} --acl "${acl}" "${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)" "s3://${ARTIFACT_BUCKET}/$(aws_s3_generate_zip_filename)"; then
    success "Successfully copied $(aws_s3_generate_zip_filename) to s3://${ARTIFACT_BUCKET}/$(aws_s3_generate_zip_filename)"
  else
    fail "An error occurred while copying $(aws_s3_generate_zip_filename) to s3://${ARTIFACT_BUCKET}/$(aws_s3_generate_zip_filename)"
  fi
}

#######################################
# aws_s3_download_artifact: Down the artifact ZIP file from the S3 bucket ${ARTIFACT_BUCKET}
#
# Expects:
#
# Globals:
#     * PARENT_SLUG: Set by bootstrapping bb-aws-utils
#     * BITBUCKET_REPO_SLUG: provided by BitBucket pipelines
#     * BITBUCKET_COMMIT: provided by BitBucket pipelines
#
# Arguments:
#     * key name
#     * local name relative to ${BITBUCKET_CLONE_DIR}
#
# Outputs:
#
# Returns:
#    * 0 on success
#    * exits on failure
#
#######################################
aws_s3_download_artifact() {
  check_envvar ARTIFACT_BUCKET R
  [[ -z ${1} || -z ${2} ]] && fail "aws_s3_download_artifact requires 2 arguments: key on bucket and local filename"

  info "Starting download of s3://${ARTIFACT_BUCKET}/${1} to ${2}"
  if aws s3 cp ${AWS_S3_CLI_OPTS} "s3://${ARTIFACT_BUCKET}/${1}" "${BITBUCKET_CLONE_DIR}/${2}"; then
    success "Successfully copied s3://${ARTIFACT_BUCKET}/${1} to ${2}"
  else
    fail "An error occurred while copying s3://${ARTIFACT_BUCKET}/${1} to ${2}"
  fi
}

#######################################
# aws_s3_update_artifact: Download the artifact ZIP file from S3 using the aws_s3_download_artifact
#   (if not already done) and add the file (1st argument) inside the ZIP as 2nd argument.
#
# Expects:
#     * To be used in configuration repositories (i.e. my-project.config.stg)
#     * TAG file should exist in the repo, and is used to construct the filename to download
#     * The source and target bucket is defined by the envvar ARTIFACT_BUCKET
#     * Can be called multiple times, 1x for each file to add
#
# Globals:
#
# Arguments:
#     * Relative path of the file to add
#     * Path of the file inside the ZIP (without the filename)
#
# Outputs:
#
# Returns:
#
#######################################
aws_s3_update_artifact() {
  install_zip
  [[ -z ${1} || -z ${2} ]] && fail "aws_s3_update_artifact requires 2 arguments: file to add to zip and path inside the zip"

  if [[ ! -e "${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)" ]]; then
    aws_s3_download_artifact "$(aws_s3_generate_parent_zip_filename)" "$(aws_s3_generate_zip_filename)"
  fi

  # Create the tree where the file should end up in the zipfile (i.e. ${2})
  info "Create workdir an destination tree for the file to add to the ZIP"
  mkdir -p "workdir/${2}"
  info "Copy file ${1} to workdir/${2}"
  cp "${BITBUCKET_CLONE_DIR}/${1}" "workdir/${2}"
  info "Add ${2}/${1} to ${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)"
  (cd workdir && zip -ur "${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)" .)
  info "Cleanup workdir"
  rm -rf workdir
  success "Successfully added ${1} to ${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename) in path ${2}"
}

#######################################
# aws_s3_deploy_artifact: Download the artifact ZIP file from S3 using the aws_s3_download_artifact
#   unzip the file and deploy it to the destination S3 bucket
#
# Expects:
#     * TAG file should exist in the repo, and is used to construct the filename to download
#     * The source and target bucket is defined by the envvar ARTIFACT_BUCKET
#     * Can be called multiple times, 1x for each file to add
#     * The destination bucket is retrieved from the SSM Parameter store parameter passed in AWS_SSM_S3_DEST_BUCKET
#
# Globals:
#     * S3_DEST_PREFIX (optional, defaults to empty string): Should be set in pipeline or in pipeline variable
#     * AWS_SSM_S3_DEST_BUCKET: Should be set in pipeline or in pipeline variable
#
# Arguments:
#     * Relative path of the file to add
#     * Path of the file inside the ZIP (without the filename)
#
# Outputs:
#
# Returns:
#
#######################################
aws_s3_deploy_artifact() {
  check_envvar S3_DEST_PREFIX O
  install_zip

  local dest_bucket

  aws_s3_download_artifact "$(aws_s3_generate_zip_filename)" "$(aws_s3_generate_zip_filename)"
  if [[ -n "${S3_DEST_BUCKET}" ]]; then
    dest_bucket="${S3_DEST_BUCKET}"
  elif [[ -n "${AWS_SSM_S3_DEST_BUCKET}" ]]; then
    info "Retrieve the SSM parameter ${AWS_SSM_S3_DEST_BUCKET} from the parameter store"
    dest_bucket=$(aws_get_ssm_parameter_by_name "${AWS_SSM_S3_DEST_BUCKET}")
    success "Destination bucket ${dest_bucket} successfully retrieved from AWS SSM Parameter Store"
  else
    fail "Unable to determine destination bucket because S3_DEST_BUCKET nor AWS_SSM_S3_DEST_BUCKET are set."
  fi
  info "Unzip the zipfile in workdir"
  (mkdir workdir && cd workdir && unzip "${BITBUCKET_CLONE_DIR}/$(aws_s3_generate_zip_filename)")
  info "Recursively deploy the content of workdir to s3://${dest_bucket}/${S3_DEST_PREFIX:-}."
  (cd workdir && aws s3 cp ${AWS_S3_CLI_OPTS} --acl private --recursive . "s3://${dest_bucket}/${S3_DEST_PREFIX:-}")
  success "Deploy was successful."

  info "Cleaning up ..."
  rm -rf workdir
  success "Successfully cleaned up workdir"
}
